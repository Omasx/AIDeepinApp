import asyncio
import logging
import itertools
from typing import List, Dict, Optional, Any
from dataclasses import dataclass

logger = logging.getLogger("AOI-Swarm-Router")

@dataclass
class APIKey:
    provider: str
    key: str
    rate_limit: int = 5  # Requests per second default

class APIRouter:
    """
    1. The Core Engine: Multi-Key Load Balancer
    Ø§Ù„Ù…Ø³Ø¤ÙˆÙ„ÙŠØ©: ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø·Ù„Ø¨Ø§Øª Ø¹Ù„Ù‰ Ø§Ù„Ù…ÙØ§ØªÙŠØ­ Ø§Ù„Ù…ØªØ§Ø­Ø© Ù„ØªÙ‚Ù„ÙŠÙ„ Ø²Ù…Ù† Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± ÙˆØªØ¬Ù†Ø¨ Ø§Ù„Ù€ Rate Limits.
    """
    def __init__(self, keys: List[APIKey]):
        self.keys = keys
        self.key_cycle = itertools.cycle(keys) if keys else None
        
        # Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ Ù…ÙØªØ§Ø­ ÙˆØ§Ø­Ø¯ØŒ Ù†Ø³ØªØ®Ø¯Ù… Semaphore Ù„Ù„ØªØ­ÙƒÙ… ÙÙŠ Ø§Ù„ØªØ¯ÙÙ‚
        # Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ Ø¹Ø¯Ø© Ù…ÙØ§ØªÙŠØ­ØŒ Ù†ÙˆØ²Ø¹ Ø§Ù„Ø­Ù…Ù„ Ø¨ÙŠÙ†Ù‡Ù…
        self.semaphore = asyncio.Semaphore(len(keys) * 5 if keys else 1)
        
        logger.info(f"ðŸ”Œ APIRouter initialized with {len(keys)} keys.")

    async def call_llm(self, prompt: str, model: str = "llama3.5") -> str:
        """
        ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø·Ù„Ø¨ Ø¹Ù„Ù‰ Ø£ÙØ¶Ù„ Ù…ÙØªØ§Ø­ Ù…ØªØ§Ø­ (Round-Robin).
        """
        async with self.semaphore:
            if not self.keys:
                logger.warning("âš ï¸ No API keys configured. Using local fallback.")
                return await self._local_fallback(prompt)

            target_key = next(self.key_cycle)
            logger.info(f"ðŸ“¡ Dispatching request to {target_key.provider} via key ending in ...{target_key.key[-4:]}")
            
            # Ù…Ø­Ø§ÙƒØ§Ø© Ø²Ù…Ù† Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø³Ø±ÙŠØ¹ Ø¬Ø¯Ø§Ù‹ Ù„ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ù€ Latency
            # ÙÙŠ Ø§Ù„Ø­Ù‚ÙŠÙ‚Ø© Ù‡Ù†Ø§ ÙŠØªÙ… Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ OpenAI API Ø£Ùˆ Groq Ø£Ùˆ ØºÙŠØ±Ù‡
            await asyncio.sleep(0.1) 
            return f"Response from {target_key.provider} for: {prompt[:20]}..."

    async def _local_fallback(self, prompt: str) -> str:
        # Ù…Ø­Ø§ÙƒØ§Ø© Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ù…Ù† Ù†Ù…ÙˆØ°Ø¬ Ù…Ø­Ù„ÙŠ (Ollama/llama.cpp)
        await asyncio.sleep(0.5)
        return f"Local Llama Response to: {prompt[:20]}"

    def add_key(self, provider: str, key: str):
        self.keys.append(APIKey(provider, key))
        self.key_cycle = itertools.cycle(self.keys)
        self.semaphore = asyncio.Semaphore(len(self.keys) * 5)
        logger.info(f"âž• New key added. Total keys: {len(self.keys)}")
