# download_llama.py - Ø³ÙƒØ±ÙŠØ¨Øª ØªØ­Ù…ÙŠÙ„ Ø£ÙˆØ²Ø§Ù† Llama 3.5
import os
import requests
from tqdm import tqdm

def download_file(url, destination):
    print(f"ğŸ“¥ Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„: {url}")
    response = requests.get(url, stream=True)
    total_size = int(response.headers.get('content-length', 0))
    
    with open(destination, "wb") as f, tqdm(
        total=total_size, unit='B', unit_scale=True, desc=destination
    ) as pbar:
        for data in response.iter_content(chunk_size=1024*1024):
            f.write(data)
            pbar.update(len(data))

def main():
    # Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ (Ø£Ù…Ø«Ù„Ø©)
    models = {
        "Llama-3.5-70B-int8": "https://huggingface.co/meta-llama/Llama-3.5-70B/resolve/main/model.safetensors",
        "Llama-3.5-8B-GGUF": "https://huggingface.co/TheBloke/Llama-3.5-8B-GGUF/resolve/main/llama-3.5-8b.Q4_K_M.gguf"
    }
    
    print("ğŸš€ Ù…Ø­Ù…Ù„ Ù†Ù…Ø§Ø°Ø¬ Llama 3.5 AGI")
    print("-" * 30)
    
    weights_dir = "llama3.5/weights"
    if not os.path.exists(weights_dir):
        os.makedirs(weights_dir)
        
    print("1. Llama-3.5-70B (13GB+)")
    print("2. Llama-3.5-8B (5GB+)")
    
    # Ù…Ø­Ø§ÙƒØ§Ø©: ÙÙŠ Ø§Ù„ÙˆØ§Ù‚Ø¹ Ø³Ù†Ø·Ù„Ø¨ Ù…Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª
    print("\n[Ø³ÙŠØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø­Ø¯Ø¯ ÙˆÙˆØ¶Ø¹Ù‡ ÙÙŠ llama3.5/weights/]")
    
if __name__ == "__main__":
    main()
